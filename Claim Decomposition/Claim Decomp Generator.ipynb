{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8628931,"sourceType":"datasetVersion","datasetId":5159395},{"sourceId":8639063,"sourceType":"datasetVersion","datasetId":5173626},{"sourceId":182830995,"sourceType":"kernelVersion"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-13T11:31:00.059443Z","iopub.execute_input":"2024-06-13T11:31:00.06002Z","iopub.status.idle":"2024-06-13T11:31:00.578142Z","shell.execute_reply.started":"2024-06-13T11:31:00.059966Z","shell.execute_reply":"2024-06-13T11:31:00.576693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-06-13T11:31:00.580385Z","iopub.execute_input":"2024-06-13T11:31:00.580907Z","iopub.status.idle":"2024-06-13T11:31:06.265731Z","shell.execute_reply.started":"2024-06-13T11:31:00.580854Z","shell.execute_reply":"2024-06-13T11:31:06.264295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\nimport json\n\nmodel_dir = \"/kaggle/input/claim-decomp/Model/checkpoint-1200\"\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\n\n# Load the model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T11:31:06.267831Z","iopub.execute_input":"2024-06-13T11:31:06.268362Z","iopub.status.idle":"2024-06-13T11:31:48.196675Z","shell.execute_reply.started":"2024-06-13T11:31:06.268304Z","shell.execute_reply":"2024-06-13T11:31:48.195412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-13T11:31:48.198524Z","iopub.execute_input":"2024-06-13T11:31:48.199437Z","iopub.status.idle":"2024-06-13T11:31:48.210083Z","shell.execute_reply.started":"2024-06-13T11:31:48.19938Z","shell.execute_reply":"2024-06-13T11:31:48.208813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input claims : \ntraining_claims = []\nvalidation_claims = []\nwith open(\"/kaggle/input/testclaimsnlp/train_claims_quantemp.json\") as f:\n    train_data = json.load(f)\n    \nwith open(\"/kaggle/input/quantemp-bm25-reranked/val_claims_quantemp_bm25.json\") as f:\n    val_data = json.load(f)\n\nfor index, fact in enumerate(train_data):\n    claim = fact[\"claim\"]\n    training_claims.append(claim)\n    \nfor index, fact in enumerate(val_data):\n    claim = fact[\"claim\"]\n    validation_claims.append(claim)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T11:31:48.213258Z","iopub.execute_input":"2024-06-13T11:31:48.213644Z","iopub.status.idle":"2024-06-13T11:31:48.67165Z","shell.execute_reply.started":"2024-06-13T11:31:48.213613Z","shell.execute_reply":"2024-06-13T11:31:48.670498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_output(test_samples, model):\n    inputs = tokenizer(\n        test_samples,\n        max_length=128,\n        return_tensors=\"pt\")\n\n    input_ids = inputs.input_ids.to(model.device)\n    attention_mask = inputs.attention_mask.to(model.device)\n    outputs = model.generate(input_ids, attention_mask=attention_mask,min_length = 64, max_length = 128, do_sample=True, top_p=0.95, top_k=50)\n    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    return output_str","metadata":{"execution":{"iopub.status.busy":"2024-06-13T11:31:48.673119Z","iopub.execute_input":"2024-06-13T11:31:48.673584Z","iopub.status.idle":"2024-06-13T11:31:48.68081Z","shell.execute_reply.started":"2024-06-13T11:31:48.673536Z","shell.execute_reply":"2024-06-13T11:31:48.679644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_subquestions = []\nvalidation_subquestions = []\n\n# Here, we split the training and validation datasets into parts to prevent timeouts in kaggle\nfor claim in training_claims[1000:1500]:\n    training_subquestions.append(generate_output(\"decompose the compositional question:\"+claim, model))\n    \nfor claim in validation_claims[1000:1500]:\n    validation_subquestions.append(generate_output(\"decompose the compositional question:\"+claim, model))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-13T11:31:48.682888Z","iopub.execute_input":"2024-06-13T11:31:48.683504Z","iopub.status.idle":"2024-06-13T11:32:19.484686Z","shell.execute_reply.started":"2024-06-13T11:31:48.68347Z","shell.execute_reply":"2024-06-13T11:32:19.482993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfor index, q in enumerate(training_subquestions):\n    # The string inside the array\n    text = q[0]\n\n    # Using regex to extract questions\n    questions = re.findall(r'Question \\d+: (.*?)(?= Answer \\d+:)', text)\n\n    # Creating a dictionary with questions\n    questions_dict = {f\"Question {i}\": question.strip() for i, question in enumerate(questions)}\n    \n    train_data[1000+index]['subquestions'] = questions_dict\n    \nfor index, q in enumerate(validation_subquestions):\n    # The string inside the array\n    text = q[0]\n\n    # Using regex to extract questions\n    questions = re.findall(r'Question \\d+: (.*?)(?= Answer \\d+:)', text)\n\n    # Creating a dictionary with questions\n    questions_dict = {f\"Question {i}\": question.strip() for i, question in enumerate(questions)}\n    \n    val_data[index]['subquestions'] = questions_dict","metadata":{"execution":{"iopub.status.busy":"2024-06-13T11:32:19.486373Z","iopub.status.idle":"2024-06-13T11:32:19.486942Z","shell.execute_reply.started":"2024-06-13T11:32:19.48665Z","shell.execute_reply":"2024-06-13T11:32:19.486673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('test_data.json', 'w') as f:\n    json.dump(train_data, f)\n    \nwith open('validation_data_subquestions.json', 'w') as f:\n    json.dump(val_data, f)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T11:32:19.488186Z","iopub.status.idle":"2024-06-13T11:32:19.488552Z","shell.execute_reply.started":"2024-06-13T11:32:19.488381Z","shell.execute_reply":"2024-06-13T11:32:19.488396Z"},"trusted":true},"execution_count":null,"outputs":[]}]}